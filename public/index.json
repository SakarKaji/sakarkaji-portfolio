[{"content":" View Project ‚Üó Intro Ayomomo is a web platform created for Nepali restaurants in United Kingdom specializing in authentic dumplings (momo). It was initiated by UK based Nepali chef Binod Baral.\nMany Nepalese living UK miss the authentic taste of their comfort food, and Ayomomo solves this by providing genuine momo that taste like home.\nThe goal of this project is connecting the Nepalese community to their culture as well as introduce Nepali cuisine to international food lovers.\nüõ† Tech Stack Backend: Django (Python), Django REST Framework (DRF) Cloud Services: AWS EC2 (hosted backend), S3 (for static/media files), CloudFront (CDN) Deployment: Docker, GitHub Actions CI/CD Database: PostgreSQL (via AWS RDS) Task Queue: Celery + Redis (for background jobs) ‚öôÔ∏è How It Works Restaurant Flow Sign Up: Restaurants register using a form, providing details like restaurant name, business phone number, location, and logo. Approval: Admin reviews and approves the restaurant. Menu Management: Once approved, restaurants can post their menu items and prices. Order Notifications: When customers place orders, restaurants receive emails for each food item ordered, ensuring they prepare the correct items. Customer Flow Sign Up \u0026amp; Verification: Customers register via a form with OTP email verification (handled asynchronously by Celery) or Google Sign-In. Browse Restaurants: After account creation, customers can browse and choose nearby restaurants. Place Orders: Customers place orders, selecting either delivery (cash on delivery) or pickup. Multi-Restaurant Orders: Customers can order from multiple restaurants in a single order. They receive a single consolidated email with all items, while each restaurant receives emails only for their specific items. Key Features / Backend Handling Multi-vendor support: Each restaurant manages its menu and receives orders independently. OTP verification \u0026amp; email notifications: Managed asynchronously using Celery. Delivery vs pickup: Flexible ordering options for customers. Order management: Ensures correct email notifications to restaurants and customers. üöÄ Final Thoughts Building Ayomomo was a journey where I designed and deployed a production-ready system from backend to cloud.\nAlong the way, I implemented CI/CD pipelines, asynchronous task management, and scalable architecture.\n","permalink":"http://localhost:1313/projects/ayomomo/","summary":"View Project ‚Üó Intro Ayomomo is a web platform created for Nepali restaurants in United Kingdom specializing in authentic dumplings (momo). It was initiated by UK based Nepali chef Binod Baral.\nMany Nepalese living UK miss the authentic taste of their comfort food, and Ayomomo solves this by providing genuine momo that taste like home.\nThe goal of this project is connecting the Nepalese community to their culture as well as introduce Nepali cuisine to international food lovers.","title":"Ayomomo"},{"content":" View Project ‚Üó Intro Bizzyone is an online marketplace for commercial real estate which provides a platform where buyers, sellers, agents, and admins interact seamlessly.\nIn Nepal, real estate pricing is highly inconsistent, with sellers often quoting random rates and brokers charging excessive commissions and this lack of transparency creates confusion, mistrust, and unfair deals for both buyers and sellers.\nBizzyone solves this by providing a transparent, standardized, and centralized platform for real estate transactions.\nüõ† Tech Stack Backend: Flask (Python), Flask-RESTful APIs Database: PostgreSQL (hosted on DigitalOcean) Cloud Services: DigitalOcean Droplets (servers), Spaces (bucket storage) Task Queue: Celery + Redis (for background jobs like email notifications, OTPs) Deployment: Docker, GitHub Actions CI/CD Authentication: Email/OTP (Celery), Google Sign-In, Apple Sign-In ‚öôÔ∏è How It Works Seller Flow Sellers sign up via form, Google, or Apple login. Create listings (for rent, urgent sale, or standard sale) with property details: photos, floor plans, maps, and financials. Agent Support: Sellers can also assign listings to agents, including broker/agent details. Admin Moderation: Listings are reviewed by admins and faulty ones can be rejected. Buyer Flow Buyers register through form, Google, or Apple login. Search listings with advanced filters (category, price, property type). Post requirements such as ‚ÄúLooking to buy retail space‚Äù or ‚ÄúNeed industrial warehouse.‚Äù Contact sellers/agents directly through the platform. Subscription Model Basic: 3 listings per week, standard support. Standard: 10 listings per week, includes featured listings. Premium: Unlimited listings + advanced advertising \u0026amp; marketing tools. Admin \u0026amp; Manager Flow Admins manage users, listings, and subscriptions. Moderation system ensures only high-quality, fraud-free listings. Analytics \u0026amp; oversight to track platform activity and performance. üöÄ Final Thoughts Bizzyone is the live output of this project‚Äîan operational, subscription-based real estate marketplace for Nepal.\nThrough this project, I strengthened my expertise in multi-role systems and scalable backend services\n","permalink":"http://localhost:1313/projects/bizzyone/","summary":"View Project ‚Üó Intro Bizzyone is an online marketplace for commercial real estate which provides a platform where buyers, sellers, agents, and admins interact seamlessly.\nIn Nepal, real estate pricing is highly inconsistent, with sellers often quoting random rates and brokers charging excessive commissions and this lack of transparency creates confusion, mistrust, and unfair deals for both buyers and sellers.\nBizzyone solves this by providing a transparent, standardized, and centralized platform for real estate transactions.","title":"Bizzyone"},{"content":" View Project ‚Üó Intro Thinkmart is a multi-vendor online grocery marketplace in Australia, making Nepali and other ethnic products easy to find while letting vendors manage their products, deals, and deliveries.\nIt solves the problem of customers struggling to find familiar products in one place and helps small stores sell online without building their own system.\nWith features like product syncing, secure Stripe payments, daily deals, and admin-approved vendor sign-up, Thinkmart offers an easy and smooth experience for both customers and vendors.\nüõ† Tech Stack Backend: Django (Python), Django REST Framework (DRF) Cloud Services: AWS EC2 (hosted backend), S3 (for static/media files), CloudFront (CDN) Deployment: Docker, GitHub Actions CI/CD Database: PostgreSQL (via AWS RDS) Task Queue: Celery (for sending otp) ‚öôÔ∏è How It Works Vendor Flow Sign Up: Vendors register using a form, providing store details, location, images, and other necessary information.\nApproval: Admin reviews and approves the vendor before their products are listed.\nProduct Management: Once approved, vendors can add, edit, and manage products, set discounts, and create ‚ÄúToday‚Äôs Deals.‚Äù\nEPOS Integration: Vendors can sync products and inventory with EPOS Now to keep online and in-store catalogs consistent.\nCustomer Flow Sign Up \u0026amp; Verification: Customers register via a form with OTP email verification (handled asynchronously by Celery) or Google Sign-In.\nBrowse Products: Customers can browse products by category, deals, or offers.\nWishlist \u0026amp; Cart: Customers can add products to their wishlist or cart for later purchase.\nPlace Orders: Customers checkout securely using Stripe and can order from multiple vendors in one transaction.\nOrder Notifications: Customers receive emails with details of the products they ordered, including prices and vendor information.\nKey Features / Backend Handling Multi-vendor support: Each vendor manages their own products, discounts, and delivery rules.\nOTP verification \u0026amp; email notifications: Managed asynchronously using Celery.\nDeals \u0026amp; Offers: ‚ÄúToday‚Äôs Deals‚Äù and special offers highlight discounted products.\nPayment Integration: Stripe enables secure and seamless customer payments.\nEPOS Sync: Bi-directional product and inventory flow between Thinkmart and vendor POS.\nOrder Emails: Customers get detailed emails for every order they place, showing products and prices.\nüöÄ Final Thoughts Thinkmart bridges a real market gap: it brings community-specific grocery catalogs (like Nepali products) into a modern, scalable marketplace while staying inclusive of all vendors.\nWith a robust AWS + Django/DRF backbone, async tasking via Celery, Stripe payments, and EPOS Now syncing, the platform balances customer convenience with vendor autonomy‚Äîand sets the stage for sustainable growth across Australian suburbs and beyond.\n","permalink":"http://localhost:1313/projects/thinkmart/","summary":"View Project ‚Üó Intro Thinkmart is a multi-vendor online grocery marketplace in Australia, making Nepali and other ethnic products easy to find while letting vendors manage their products, deals, and deliveries.\nIt solves the problem of customers struggling to find familiar products in one place and helps small stores sell online without building their own system.\nWith features like product syncing, secure Stripe payments, daily deals, and admin-approved vendor sign-up, Thinkmart offers an easy and smooth experience for both customers and vendors.","title":"Thinkmart"},{"content":"\u0026ndash;\nGet App ‚Üó Intro QuickSamachar is a multilingual news delivery platform built to aggregate real-time content from major Nepali and Indian news sources\nElderly users and specially-abled users face challenges in reading or navigating conventional apps.\nThis app converts news into audio using Edge TTS and delivers organized articles along with daily horoscopes and trending short videos through a fast, cloud-powered backend, making content accessible to elderly users, specially-abled users, and anyone who prefers listening.\nüõ† Tech Stack Backend: Django (Python), Django REST Framework (DRF) Scraping: Scrapy (for Nepali \u0026amp; Indian news sources) Cloud \u0026amp; Hosting: AWS EC2 (hosted backend), AWS EC2, S3 (audio \u0026amp; media storage), CloudFront (CDN) Task Automation: Docker, Celery, GitHub Actions Database: PostgreSQL (via AWS RDS) Audio Conversion: Edge TTS (Nepali \u0026amp; English) ‚öôÔ∏è How It Works Flow News Collection: Scrapy crawls ~50 news sources, fetching cover images, titles and descriptions in Nepali and English .\nHoroscope Collection: Daily Nepali and English horoscopes are scraped and displayed in the app.\nTrending Videos: The app scrapes trending Nepali videos and displays them in the ‚ÄúShorts‚Äù section for quick updates.\nContent Storage: VNews, horoscope, and video metadata are stored in PostgreSQL for 7 days, then refreshed automatically.\nStorage \u0026amp; Delivery: Audio and media files are stored in AWS S3 and served via CloudFront for fast streaming.\nUser Features Users can select their preferred language: Nepali, English, or both.\nElderly users can listen to news instead of reading.\nSpecially-abled users, including visually impaired people, can fully access news content via audio.\nüöÄ Final Thoughts QuickSamachar bridges a critical accessibility gap in news delivery for Nepali users, including the elderly and visually impaired.\nBy combining web scraping, cloud storage, TTS audio, and multilingual support, its AWS + Django + Scrapy + Edge TTS backend ensures scalable, real-time news delivery with a smooth and user-friendly mobile experience on iOS and Android.\n","permalink":"http://localhost:1313/projects/quicksamachar/","summary":"\u0026ndash;\nGet App ‚Üó Intro QuickSamachar is a multilingual news delivery platform built to aggregate real-time content from major Nepali and Indian news sources\nElderly users and specially-abled users face challenges in reading or navigating conventional apps.\nThis app converts news into audio using Edge TTS and delivers organized articles along with daily horoscopes and trending short videos through a fast, cloud-powered backend, making content accessible to elderly users, specially-abled users, and anyone who prefers listening.","title":"QuickSamachar"},{"content":" Explore Repo ‚Üó Intro QuickGPT is a conversational document assistant that lets users upload PDFs and interact with them through natural language queries.\nIt addresses the challenge of extracting precise insights from large text collections by combining Large Language Models (LLMs) with Retrieval-Augmented Generation (RAG).\nThe result is a system that delivers context-aware answers quickly, reducing manual searching and making research, legal analysis, and reporting more efficient.\nüõ† Tech Stack Core: Python, Streamlit LLM \u0026amp; Embeddings: Ollama with Microsoft‚Äôs phi-3 and Meta\u0026rsquo;s llama-3-8b model and snowflake-arctic-embed Retrieval: Qdrant (vector database) Architecture: Retrieval-Augmented Generation (RAG) pipeline Other Tools: Prompt engineering and fine-tuning ‚öôÔ∏è How It Works Upload Documents: Users upload PDFs or text files through the Streamlit interface. Embedding \u0026amp; Storage: Documents are converted into vector embeddings using Ollama‚Äôs embedding models and stored in Qdrant. User Query: Users ask natural language questions in the chat UI. Retrieval: The RAG pipeline fetches the most relevant document chunks from Qdrant. LLM Response: The Ollama-powered LLM processes the query and retrieved context to generate accurate, context-specific answers. Output: Users receive responses directly in conversational format, eliminating the need for manual search. üöÄ Final Thoughts QuickGPT streamlines information retrieval from large documents, making it useful for academia, law, medicine, and business. Its LLM + RAG architecture ensures fast, context-aware answers while maintaining strict document boundaries for accuracy.\nBy leveraging Ollama, Qdrant, and Streamlit, QuickGPT provides an intuitive way to ‚Äúchat with your PDFs,‚Äù boosting productivity and accessibility across domains.\n","permalink":"http://localhost:1313/projects/quickgpt/","summary":"Explore Repo ‚Üó Intro QuickGPT is a conversational document assistant that lets users upload PDFs and interact with them through natural language queries.\nIt addresses the challenge of extracting precise insights from large text collections by combining Large Language Models (LLMs) with Retrieval-Augmented Generation (RAG).\nThe result is a system that delivers context-aware answers quickly, reducing manual searching and making research, legal analysis, and reporting more efficient.\nüõ† Tech Stack Core: Python, Streamlit LLM \u0026amp; Embeddings: Ollama with Microsoft‚Äôs phi-3 and Meta\u0026rsquo;s llama-3-8b model and snowflake-arctic-embed Retrieval: Qdrant (vector database) Architecture: Retrieval-Augmented Generation (RAG) pipeline Other Tools: Prompt engineering and fine-tuning ‚öôÔ∏è How It Works Upload Documents: Users upload PDFs or text files through the Streamlit interface.","title":"QuickGPT"},{"content":" Explore Repo ‚Üó Intro MadMax is an AI Enabled Voice Assistant leveraging neural networks, voice recognition, and NLP to help students quickly access and interact with their coursework using natural language. It provides a simple, conversational interface that makes learning more engaging, personalized, and efficient.\nStudents often face challenges such as limited access to personalized assistance, difficulty managing study time, and lack of engagement with course material. Traditional learning methods may not address these issues effectively, leading to decreased motivation and lower academic performance.\nMadMax solves these challenges by providing a voice-based assistant that answers coursework-related queries, offers personalized guidance, and helps students manage their study time efficiently.\nIt allows students to interact naturally without navigating complex web pages or apps, making education more engaging, accessible and convenient.\nüõ† Tech Stack Core: Python, Neural Networks, NLP Frontend: Electron, HTML, CSS, JavaScript Voice Processing: Speech-to-Text (STT) + Text-to-Speech (TTS) Data Handling: JSON for course metadata and structured responses ‚öôÔ∏è How It Works Flow Voice Input: User speaks a query related to coursework. Speech-to-Text: The system converts spoken language into text. NLP + Neural Network Processing: Text is analyzed to understand intent and fetch the correct response. Response Generation: The assistant retrieves course-related information or provides task management support. Voice Output: The system replies back in natural language, allowing hands-free interaction. Key Features Provides time, date, and temperature updates. Performs Google searches. Scrapes Wikipedia and other sources for computer science content. Responds to queries related to coursework and study material. Acts as a dictionary for word meanings. üöÄ Final Thoughts The AI Enabled Voice Assistant demonstrates how AI and NLP can enhance education by making coursework more accessible and engaging.\nIt provides a foundation for building intelligent, personalized study assistants that can be expanded to cover more subjects and courses like Arts, Finance, Management and more, integrate with online resources, and further support time management.\nFuture improvements could include expanding the course knowledge base, integrating multi-modal dialogues with visual inputs/outputs, and advancing NLP capabilities for more accurate responses.\n","permalink":"http://localhost:1313/projects/ai-enabled-voice-assistant/","summary":"Explore Repo ‚Üó Intro MadMax is an AI Enabled Voice Assistant leveraging neural networks, voice recognition, and NLP to help students quickly access and interact with their coursework using natural language. It provides a simple, conversational interface that makes learning more engaging, personalized, and efficient.\nStudents often face challenges such as limited access to personalized assistance, difficulty managing study time, and lack of engagement with course material. Traditional learning methods may not address these issues effectively, leading to decreased motivation and lower academic performance.","title":"Madmax - AI enabled voice assistant"},{"content":"Description Designing backend systems with cloud technology that are fast, scalable, and built for impact.\n","permalink":"http://localhost:1313/experience/software_engineer/","summary":"Description Designing backend systems with cloud technology that are fast, scalable, and built for impact.","title":"Software Engineer"},{"content":"Description Engineered a scalable Django backend for a news application, utilizing Django REST Framework (DRF) to create RESTful APIs for seamless interaction between the frontend and backend. Developed multiple web scraping projects to collect news from different portals across Nepal and India, ensuring up-to-date news data collection for the platform. Integrated AWS services, including RDS for PostgreSQL, S3 for media storage, and CloudFront for serving S3 content,enhancing scalability and content delivery performance. Implemented a multilingual Text-to-Speech(TTS) system for reading news in Nepali and English, enhancing accessibility and user engagement. ","permalink":"http://localhost:1313/experience/associate/","summary":"Description Engineered a scalable Django backend for a news application, utilizing Django REST Framework (DRF) to create RESTful APIs for seamless interaction between the frontend and backend. Developed multiple web scraping projects to collect news from different portals across Nepal and India, ensuring up-to-date news data collection for the platform. Integrated AWS services, including RDS for PostgreSQL, S3 for media storage, and CloudFront for serving S3 content,enhancing scalability and content delivery performance.","title":"Associate Software Engineer"},{"content":"Description Conducted extensive research on Large Language Models (LLMs) to determine the most effective models for specific use cases, performance and efficiency. Explored and implemented diverse embedding models, significantly enhancing overall accuracy and relevance of information in retrieval tasks. Utilized Qdrant for efficient storage and retrieval of vector embeddings, improving the performance of the Retrieval Augmented Generation (RAG) pipeline. Designed and fine-tuned prompts, ensuring high-quality, contextually accurate and high-quality responses tailored to diverse use cases. ","permalink":"http://localhost:1313/experience/intern/","summary":"Description Conducted extensive research on Large Language Models (LLMs) to determine the most effective models for specific use cases, performance and efficiency. Explored and implemented diverse embedding models, significantly enhancing overall accuracy and relevance of information in retrieval tasks. Utilized Qdrant for efficient storage and retrieval of vector embeddings, improving the performance of the Retrieval Augmented Generation (RAG) pipeline. Designed and fine-tuned prompts, ensuring high-quality, contextually accurate and high-quality responses tailored to diverse use cases.","title":"Python Developer Intern (LLM)"},{"content":"","permalink":"http://localhost:1313/blog/digitalocean-flask/","summary":"","title":"Connnect DigitalOcean with Flask "}]